{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here data is availble in form of images grouped based on the classes as a folder name.<br>\n",
    "Let's first get path of training and test set images as numpy array and also get all training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_dir = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training'\n",
    "test_dir = '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test'\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path) #load all files from the path\n",
    "    files = np.array(data['filenames']) #get the file  \n",
    "    targets = np.array(data['target'])#get the the classification labels as integer index\n",
    "    target_labels = np.array(data['target_names'])#get the the classification labels \n",
    "    return files,targets,target_labels\n",
    "    \n",
    "x_train, y_train,target_labels = load_dataset(train_dir)\n",
    "x_test, y_test,_ = load_dataset(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set size : ' , x_train.shape[0])\n",
    "print('Testing set size : ', x_test.shape[0])\n",
    "print('No of fruits for classification: ', len(target_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at training data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "unique,counts = np.unique(y_train, return_counts=True)#Get count for each fruit\n",
    "index = np.arange(len(target_labels))\n",
    "\n",
    "plt.figure(figsize=(15,30))\n",
    "plt.barh(index, counts)\n",
    "plt.ylabel('Fruits', fontsize=25)\n",
    "plt.xlabel('Fruits count', fontsize=25)\n",
    "plt.yticks(index, target_labels, fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training data as 80% training set and 20% validation set using scikit learn's train_test_split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.2,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"x_train shape: \" + str(x_train.shape))\n",
    "print (\"x_train shape: \" + str(y_train.shape))\n",
    "print (\"x_validate shape: \" + str(x_validate.shape))\n",
    "print (\"y_validate shape: \" + str(y_validate.shape))\n",
    "print (\"x_test shape: \" + str(x_test.shape))\n",
    "print (\"y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert images in numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "def convert_image_to_array(files):\n",
    "    images_as_array=[]\n",
    "    for file in files:\n",
    "        # Convert to Numpy Array\n",
    "        images_as_array.append(img_to_array(load_img(file)))\n",
    "    return images_as_array\n",
    "\n",
    "x_train = np.array(convert_image_to_array(x_train))\n",
    "print('Training set shape : ',x_train.shape)\n",
    "\n",
    "x_validate = np.array(convert_image_to_array(x_validate))\n",
    "print('Validation set shape : ',x_validate.shape)\n",
    "\n",
    "x_test = np.array(convert_image_to_array(x_test))\n",
    "print('Test set shape : ',x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling garbage collector to avoid memory error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale image data to (0,1) range from (0,255) range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255\n",
    "x_validate = x_validate.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have alook at some of fruit images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "\n",
    "for i in range(1,17):\n",
    "    index = np.random.randint(x_train.shape[0])\n",
    "    plt.subplot(4, 4, i)\n",
    "    plt.imshow(np.squeeze(x_train[index]), cmap='cool')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform data augmentation for generalization of training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following CNN model Convolutional layers and fully connected layers are taken from following paper:<br>\n",
    "[Fruit recognition from images using deep learning](https://www.researchgate.net/publication/321475443_Fruit_recognition_from_images_using_deep_learning)<br>\n",
    "Additon to that max pool layers, dropout layers and batch normalization layers are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16,kernel_size=(5, 5),kernel_initializer='he_normal',activation='relu',input_shape=(100,100,3),name = 'conv0'))\n",
    "model.add(BatchNormalization(name='bn0'))\n",
    "model.add(Dropout(0.2,name='dropout0'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu',name = 'conv1'))\n",
    "model.add(BatchNormalization(name='bn1'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name = 'maxpool1'))\n",
    "model.add(Dropout(0.2,name='dropout1'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), activation='relu',name = 'conv2'))\n",
    "model.add(BatchNormalization(name='bn2'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name = 'maxpool2'))\n",
    "model.add(Dropout(0.2,name='dropout2'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(5,5), activation='relu',name = 'conv3'))\n",
    "model.add(BatchNormalization(name='bn3'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name = 'maxpool3'))\n",
    "model.add(Dropout(0.2,name='dropout3'))\n",
    "\n",
    "model.add(Flatten(name='fc'))\n",
    "model.add(Dense(1024, activation='relu',name = 'Dense0'))\n",
    "model.add(Dense(256, activation='relu',name = 'Dense1'))\n",
    "model.add(Dropout(0.3,name='dropout4'))\n",
    "model.add(Dense(len(target_labels), activation='softmax',name = 'Dense2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create checkpoint to save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath = 'cnn_fruit_360.hdf5', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size= 32), epochs = 50, verbose=1,callbacks = [checkpoint],validation_data=(x_validate,y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights from the best saved model to evaluate test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('cnn_fruit_360.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test,y_test,verbose=0)\n",
    "print('Test Loss :',score[0])\n",
    "print('Test Accuracy :',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the predictions for the test data\n",
    "predicted_classes = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(y_test, predicted_classes, target_names = target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = confusion_matrix(y_true, predicted_classes) \n",
    "import itertools\n",
    "plt.imshow(confusion_mtx, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('confusion_matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_labels))\n",
    "plt.xticks(tick_marks, target_labels, rotation=90)\n",
    "plt.yticks(tick_marks, target_labels)\n",
    "#Following is to mention the predicated numbers in the plot and highligh the numbers the most predicted number for particular label\n",
    "thresh = confusion_mtx.max() / 2.\n",
    "for i, j in itertools.product(range(confusion_mtx.shape[0]), range(confusion_mtx.shape[1])):\n",
    "    plt.text(j, i, confusion_mtx[i, j],\n",
    "    horizontalalignment=\"center\",\n",
    "    color=\"white\" if confusion_mtx[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
